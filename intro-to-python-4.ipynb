{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True Learning Objectives\n",
    "\n",
    "- How can I process data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How do I process data elements in a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the knowledge of **loop** (repetitive action) and **if..else** (conditional statements), we return our focus on DataFrame, this time to examine how to perform data cleaning and preprocessing tasks. \n",
    "\n",
    "We will be using the breast cancer diagnostic data set from https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by looking at our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/breast-cancer-wisconsin.csv', header=None)\n",
    "data.columns = ['Sample code', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape',\n",
    "                'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',\n",
    "                'Normal Nucleoli', 'Mitoses','Class']\n",
    "\n",
    "print('Number of instances = %d' % (data.shape[0]))\n",
    "print('Number of attributes = %d' % (data.shape[1]))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address some issues such as duplication, we will go ahead and drop the `Sample code` column, which can be used to identify unique records in this data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Sample code'],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "From the data's website (https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)), it shows that there are missing values in the data set. Looking at the data's description (https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names), the missing values are replaced by **?**. \n",
    "\n",
    "This does not impact how Pandas sees the majority of data attributes for each records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it impacts how calculations are performed on each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.sum(np.asarray([0,1,2,3,4], dtype='int64')))\n",
    "print(np.sum(data['Bare Nuclei']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to replace **?**, which is a character, with a notation from `Numpy` to indicate that this is a missing numerical value. This notation in `Numpy` is `NaN` (not a number). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace('?',np.NaN)\n",
    "\n",
    "print('Number of instances = %d' % (data.shape[0]))\n",
    "print('Number of attributes = %d' % (data.shape[1]))\n",
    "\n",
    "print('Number of missing values:')\n",
    "for col in data.columns:\n",
    "    print('\\t%s: %d' % (col,data[col].isna().sum()))\n",
    "print (data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only column `Bare Nuclei` has missing values, and after modification, it changes from a numerical column to a generic object column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(data['Bare Nuclei']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame allows you to convert the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Bare Nuclei'] = pd.to_numeric(data['Bare Nuclei'])\n",
    "print(np.sum(data['Bare Nuclei']))\n",
    "print('Number of missing values:')\n",
    "for col in data.columns:\n",
    "    print('\\t%s: %d' % (col,data[col].isna().sum()))\n",
    "print (data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know where the missing values are, how can we preprocess them?\n",
    "- Replace missing values with median values\n",
    "- Omit missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data['Bare Nuclei']\n",
    "\n",
    "print('Before replacing missing values:')\n",
    "print(data2[20:25])\n",
    "data2 = data2.fillna(data2.median())\n",
    "\n",
    "print('\\nAfter replacing missing values:')\n",
    "print(data2[20:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data['Bare Nuclei']\n",
    "print('Before replacing missing values:')\n",
    "print(data3[20:25])\n",
    "\n",
    "data3 = data3.dropna()\n",
    "\n",
    "print('\\nAfter replacing missing values:')\n",
    "print(data3[20:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "\n",
    "Outliers are data instances with characteristics that are considerably different from the rest of the dataset. Outliers can be observed visually using boxplot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#data2 = data.drop(['Class'],axis=1)\n",
    "data.boxplot(figsize=(20,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To discard the outliers, we can compute the Z-score for each attribute and remove those instances containing attributes with abnormally high or low Z-score (e.g., if Z > 3 or Z <= -3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = (data-data.mean())/data.std()\n",
    "print (z[20:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "z1 = stats.zscore(data)\n",
    "print (z1[20:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z.shape)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SciPy** to the rescue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "data_no_outlier = data[(np.abs(stats.zscore(data)) < 3).all(axis=1)]\n",
    "print(data_no_outlier.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = data.duplicated()\n",
    "print('Number of duplicate rows = %d' % (dups.sum()))\n",
    "data.loc[[11,28]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drop duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of rows before discarding duplicates = %d' % (data.shape[0]))\n",
    "data = data.drop_duplicates()\n",
    "print('Number of rows after discarding duplicates = %d' % (data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aggregation (slide 3)**\n",
    "\n",
    "Data aggregation is a preprocessing task where the values of two or more objects are combined into a single object. The motivation for aggregation includes (1) reducing the size of data to be processed, (2) changing the granularity of analysis (from fine-scale to coarser-scale), and (3) improving the stability of the data.\n",
    "\n",
    "In the example below, we will use the daily precipitation time series data for a weather station located at Detroit Metro Airport. The raw data was obtained from the Climate Data Online website (https://www.ncdc.noaa.gov/cdo-web/). The daily precipitation time series will be compared against its monthly values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = pd.read_csv('data/DTW_prec.csv', header='infer')\n",
    "print(daily.info())\n",
    "print(daily.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert this DataFrame into a `Series`, which is an indexed vector structure in Pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily.index = pd.to_datetime(daily['DATE'])\n",
    "daily = daily['PRCP']\n",
    "print(daily.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = daily.plot(kind='line',figsize=(15,3))\n",
    "ax.set_title('Daily Precipitation (variance = %.4f)' % (daily.var()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas allows us to quickly changing the granularity of analysis through function `groupby`. The documentation of groupby for `Series` is at:\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.groupby.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly = daily.groupby(pd.Grouper(freq='M')).sum()\n",
    "ax = monthly.plot(kind='line',figsize=(15,3))\n",
    "ax.set_title('Monthly Precipitation (variance = %.4f)' % (monthly.var()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5:\n",
    "Modify the code below so that it groups the time series data by year. \n",
    "*Hint: If month is M, what will year be?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monthly = daily.groupby(pd.Grouper(freq='__')).sum()\n",
    "ax = monthly.plot(kind='line',figsize=(15,3))\n",
    "ax.set_title('Monthly Precipitation (variance = %.4f)' % (monthly.var()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sampling (slide 7)**\n",
    "\n",
    "Sampling is an approach commonly used to facilitate \n",
    "- data reduction for exploratory data analysis and scaling up algorithms to big data applications and\n",
    "- quantifying uncertainties due to varying data distributions. \n",
    "\n",
    "There are various methods available for data sampling, such as sampling without replacement, where each selected instance is removed from the dataset, and sampling with replacement, where each selected instance is not removed, thus allowing it to be selected more than once in the sample.\n",
    "\n",
    "In the example below, we will apply sampling with replacement and without replacement to the breast cancer dataset obtained from the UCI machine learning repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without replacement (no possible duplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_data = data.head(10)\n",
    "sample = tmp_data.sample(n=4)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify the fraction of data we want to sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = tmp_data.sample(frac=0.25)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With replacement (there could be duplications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = tmp_data.sample(frac=0.3, replace = True)\n",
    "sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
