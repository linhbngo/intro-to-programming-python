{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will go over several Python examples for detecting anomalies (outliers) from data. Anomaly detection is the task of identifying instances whose characteristics differ significantly from the rest of the data. In this tutorial, we will provide examples of applying different anomaly detection techniques using Python and its library packages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach assumes that the majority of the data instances are governed by some well-known probability distribution, e.g., Binomial or Gaussian distribution. Anomalies can then detected by seeking for observations that do not fit the overall distribution of the data. \n",
    "\n",
    "In this example, our goal is to detect anomalous changes in the daily closing prices of various stocks. The input data *stocks.csv* contains the historical closing prices of stocks for 3 large corporations (Microsoft, Ford Motor Company, and Bank of America). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "stocks = pd.read_csv('data/stocks.csv', header='infer' ) \n",
    "stocks.index = stocks['Date']\n",
    "stocks = stocks.drop(['Date'],axis=1)\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the percentage of changes in the daily closing price of each stock as follows:\n",
    "\\begin{equation}\n",
    "\\Delta(t) = 100 \\times \\frac{x_t - x_{t-1}}{x_{t-1}} \n",
    "\\end{equation}\n",
    "\n",
    "where $x_t$ denotes the price of a stock on day $t$ and $x_{t-1}$ denotes the price on its previous day, $t-1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "N,d = stocks.shape\n",
    "delta = pd.DataFrame(100*np.divide(stocks.iloc[1:,:].values-stocks.iloc[:N-1,:].values, stocks.iloc[:N-1,:].values),\n",
    "                    columns=stocks.columns, index=stocks.iloc[1:].index)\n",
    "delta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the distribution of the percentage daily changes in stock price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(8,5)).gca(projection='3d')\n",
    "fig.scatter(delta.MSFT,delta.F,delta.BAC)\n",
    "fig.set_xlabel('Microsoft')\n",
    "fig.set_ylabel('Ford')\n",
    "fig.set_zlabel('Bank of America')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming the data follows a multivariate Gaussian distribution, we can compute the mean and covariance matrix of the 3-dimensional data as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanValue = delta.mean()\n",
    "covValue = delta.cov()\n",
    "print(meanValue)\n",
    "print(covValue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the anomalous trading days, we can compute the Mahalanobis distance between the percentage of price change on each day against the mean percentage of price change.\n",
    "\\begin{equation}\n",
    "\\textrm{Mahalanobis}(x) = (x - \\bar{x}) \\Sigma^{-1}(x - \\bar{x})^T\n",
    "\\end{equation}\n",
    "where $x$ is assumed to be a row vector.\n",
    "\n",
    "See Equation 9.4 in Section 9.3.1 for more information about using Mahalanobis distance for detecting anomalies in multivariate Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "\n",
    "X = delta.as_matrix()\n",
    "S = covValue.as_matrix()\n",
    "for i in range(3):\n",
    "    X[:,i] = X[:,i] - meanValue[i]\n",
    "    \n",
    "def mahalanobis(row):\n",
    "    return np.matmul(row,S).dot(row)   \n",
    "    \n",
    "anomaly_score = np.apply_along_axis( mahalanobis, axis=1, arr=X)\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "p = ax.scatter(delta.MSFT,delta.F,delta.BAC,c=anomaly_score,cmap='jet')\n",
    "ax.set_xlabel('Microsoft')\n",
    "ax.set_ylabel('Ford')\n",
    "ax.set_zlabel('Bank of America')\n",
    "fig.colorbar(p)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top-2 anomalies are shown as a brown point in the figure above. The highest anomaly corresponds to the day in which the prices for all 3 stocks increase significantly whereas the second highest anomaly corresponds  to the day in which all 3 stocks suffer a large percentage drop in their closing prices. We can examine the dates associated with the top-2 highest anomaly scores as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anom = pd.DataFrame(anomaly_score, index=delta.index, columns=['Anomaly score'])\n",
    "result = pd.concat((delta,anom), axis=1)\n",
    "result.nlargest(2,'Anomaly score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the sharp drop in the stock prices on October 7, 2008 coincide with the beginning of the global financial crisis (https://en.wikipedia.org/wiki/Global_financial_crisis_in_October_2008) while the increase in the stock prices on April 9, 2009. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(nrows=1, ncols=2, figsize=(15,6))\n",
    "\n",
    "ts = delta[440:447]\n",
    "ts.plot.line(ax=ax1)\n",
    "ax1.set_xticks(range(7))\n",
    "ax1.set_xticklabels(ts.index)\n",
    "ax1.set_ylabel('Percent Change')\n",
    "\n",
    "ts = delta[568:575]\n",
    "ts.plot.line(ax=ax2)\n",
    "ax2.set_xticks(range(7))\n",
    "ax2.set_xticklabels(ts.index)\n",
    "ax2.set_ylabel('Percent Change')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance-based approach is a model-free anomaly detection approach as it does not require constructing an explicit model of the normal class to determine the anomaly score of data instances. The example code shown below employs the k-nearest neighbor approach to calculate anomaly score. Specifically, a normal instance is expected to have a small distance to its k-th nearest neighbor whereas an anomaly is likely to have a large distance to its k-th nearest neighbor. In the example below, we apply the distance-based approach with k=4 to identify the anomalous trading days from the stock market data described in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n",
    "knn = 4\n",
    "nbrs = NearestNeighbors(n_neighbors=knn, metric=distance.euclidean).fit(delta.as_matrix())\n",
    "distances, indices = nbrs.kneighbors(delta.as_matrix())\n",
    "\n",
    "anomaly_score = distances[:,knn-1]\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "p = ax.scatter(delta.MSFT,delta.F,delta.BAC,c=anomaly_score,cmap='jet')\n",
    "ax.set_xlabel('Microsoft')\n",
    "ax.set_ylabel('Ford')\n",
    "ax.set_zlabel('Bank of America')\n",
    "fig.colorbar(p)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are slightly different than the one shown in Section 9.1 since we have used Euclidean distance (instead of Mahalanobis distance) to detect the anomalies. We can examine the dates associated with the top-5 highest anomaly scores as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anom = pd.DataFrame(anomaly_score, index=delta.index, columns=['Anomaly score'])\n",
    "result = pd.concat((delta,anom), axis=1)\n",
    "result.nlargest(5,'Anomaly score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,4))\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "ts = delta[445:452]\n",
    "ts.plot.line(ax=ax)\n",
    "ax.set_xticks(range(7))\n",
    "ax.set_xticklabels(ts.index)\n",
    "ax.set_ylabel('Percent Change')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
