{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "from numpy.random import random\n",
    "\n",
    "# Two class problem, but most likely we will need to merge them into a single NumPy frame\n",
    "# when calculating, therefore\n",
    "N = 5200 + 5200\n",
    "\n",
    "# Gaussian center with diagonal variance\n",
    "meanG = [10, 10]\n",
    "cov = [[3.5, 0], [0, 3.5]]  # diagonal covariance\n",
    "\n",
    "np.random.seed(50)\n",
    "\n",
    "# 5000 instances generated from a Gaussian centered at (10,10)\n",
    "X = np.random.multivariate_normal(meanG, cov, int(N/2) - 200)\n",
    "\n",
    "# 200 noisy instances\n",
    "X = np.concatenate((X, 20*np.random.rand(200,2)))\n",
    "\n",
    "# 5200 instances generated from a uniform distribution\n",
    "X = np.concatenate((X, 20*np.random.rand(int(N/2),2)))\n",
    "\n",
    "# The first 5200 instances belong to class 1\n",
    "# The next 5200 instances belong to class 0\n",
    "Y = np.concatenate((np.ones(int(N/2)),np.zeros(int(N/2))))\n",
    "\n",
    "\n",
    "plt.plot(X[:int(N/2),0],X[:int(N/2),1],'b+',X[int(N/2):,0],X[int(N/2):,1],'r.',ms=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Training and Test set creation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.8, random_state=1)\n",
    "\n",
    "\n",
    "\n",
    "# Model fitting and evaluation\n",
    "maxdepths = [2,3,4,5,6,7,8,9,10,15,20,25,30,35,40,45,50]\n",
    "\n",
    "# Set up array to store accuracy values for training and testing activities\n",
    "# at each depth\n",
    "trainAcc = np.zeros(len(maxdepths))\n",
    "testAcc = np.zeros(len(maxdepths))\n",
    "\n",
    "index = 0\n",
    "for depth in maxdepths:\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "    clf = clf.fit(X_train, Y_train)\n",
    "    Y_predTrain = clf.predict(X_train)\n",
    "    Y_predTest = clf.predict(X_test)\n",
    "    trainAcc[index] = accuracy_score(Y_train, Y_predTrain)\n",
    "    testAcc[index] = accuracy_score(Y_test, Y_predTest)\n",
    "    index += 1\n",
    "    \n",
    "# Plot of training and test accuracies    \n",
    "plt.plot(maxdepths,trainAcc,'ro-',maxdepths,testAcc,'bv--')\n",
    "plt.legend(['Training Accuracy','Test Accuracy'])\n",
    "plt.xlabel('Max depth')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "\n",
    "To illustrate the problem of model overfitting, we consider a two-dimensional dataset containing 1000 labeled instances, each of which is assigned to one of two classes, 0 or 1. Instances from each class are generated as follows:\n",
    "\n",
    "- Instances from class 1 are generated from a mixture of 4 Gaussian distributions, centered at [5,4], [6,14], [10,6], and [14 14], respectively.\n",
    "\n",
    "- Instances from class 0 are generated from a uniform distribution in a square region, whose sides have a length equals to 20.\n",
    "\n",
    "For simplicity, both classes have equal number of labeled instances. The code for generating and plotting the data is shown below. All instances from class 1 are shown in red while those from class 0 are shown in black.\n",
    "\n",
    "Complete the cells below to generate the correct dataset and perform overfitting demonstration for **only** depths of 4, 8, 12, 16, 20, 24, 28, 32, 36, and 40. \n",
    "\n",
    "To emphasize, **only** depths of 4, 8, 12, 16, 20, 24, 28, 32, 36, and 40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "N = 1000\n",
    "\n",
    "mean0 = \n",
    "mean1 = \n",
    "mean2 = \n",
    "mean3 = \n",
    "cov = [[1.5, 0], [0, 1.5]]  # diagonal covariance\n",
    "\n",
    "np.random.seed(50)\n",
    "X = np.random.multivariate_normal(mean0, cov, ______)\n",
    "X = np.concatenate((X, np.random.multivariate_normal(mean1, cov, _______)))\n",
    "X = np.concatenate((X, np.random.multivariate_normal(___________________)))\n",
    "X = np.concatenate((X, np.random.multivariate_normal(___________________)))\n",
    "X = np.concatenate((X, 20*np.random.rand(______,2)))\n",
    "\n",
    "Y = np.concatenate((np.ones(______),np.zeros(______)))\n",
    "\n",
    "plt.plot(X[:int(N/2),0],X[:int(N/2),1],'r+',X[int(N/2):,0],X[int(N/2):,1],'k.',ms=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Test set creation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.8, random_state=1)\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Model fitting and evaluation\n",
    "\n",
    "\n",
    "maxdepths = [4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40]\n",
    "\n",
    "trainAcc = np.zeros(len(maxdepths))\n",
    "testAcc = np.zeros(len(maxdepths))\n",
    "\n",
    "index = 0\n",
    "for depth in maxdepths:\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "    clf = clf.fit(X_train, Y_train)\n",
    "    Y_predTrain = clf.predict(X_train)\n",
    "    Y_predTest = clf.predict(X_test)\n",
    "    trainAcc[____] = accuracy_score(Y_train, Y_predTrain)\n",
    "    testAcc[____] = accuracy_score(Y_test, Y_predTest)\n",
    "    index = _____\n",
    "    \n",
    "#########################################\n",
    "# Plot of training and test accuracies\n",
    "#########################################\n",
    "    \n",
    "plt.plot(maxdepths,trainAcc,'ro-',maxdepths,testAcc,'bv--')\n",
    "plt.legend(['Training Accuracy','Test Accuracy'])\n",
    "plt.xlabel('Max depth')\n",
    "plt.ylabel('Accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
